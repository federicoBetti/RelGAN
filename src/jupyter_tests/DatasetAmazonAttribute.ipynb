{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\Documents\\GitHub\\relgan\\src\\jupyter_tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\Documents\\GitHub\\relgan\\src\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "assert cwd.endswith(\"src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis on the Amazon Attribute dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from utils.text_process import get_word_list, get_dict, text_to_code\n",
    "from path_resolution import resources_path\n",
    "from utils.static_file_manage import write_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = resources_path(\"data\", \"Amazon_Attribute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(data_dir, 'full_datasets', 'train.txt'), sep=\"\\t\", header=None)\n",
    "data.columns = [\"user_id\", \"product_id\", \"rating\", \"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute product_ids and user_ids to remove because they occur too few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "product_count = data['product_id'].value_counts()\n",
    "product_id_keep = product_count[product_count.apply(lambda x: x>15)].index\n",
    "\n",
    "user_count = data['user_id'].value_counts()\n",
    "user_id_keep = user_count[user_count.apply(lambda x: x>6)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_low_index(df, user_id_keep, product_id_keep):\n",
    "    df = df[df['user_id'].isin(user_id_keep)]\n",
    "    return df[df.product_id.isin(product_id_keep)]\n",
    "\n",
    "from collections import Counter \n",
    "def removeElements(lst, k): \n",
    "    counted = Counter(lst) \n",
    "    return [el for el in lst if counted[el] >= k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148282/148282 [00:49<00:00, 3001.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63095/63095 [00:19<00:00, 3242.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22644/22644 [00:07<00:00, 3119.48it/s]\n"
     ]
    }
   ],
   "source": [
    "token_list = []\n",
    "dataframes = []\n",
    "file_names = ['train.txt', 'test.txt', 'dev.txt']\n",
    "for file_name in file_names:\n",
    "    data_tmp = pd.read_csv(join(data_dir, 'full_datasets',file_name), sep=\"\\t\", header=None)\n",
    "    data_tmp.columns = [\"user_id\", \"product_id\", \"rating\", \"review\"]\n",
    "    data_tmp = remove_low_index(data_tmp, user_id_keep, product_id_keep)\n",
    "    for text in tqdm(data_tmp.review):\n",
    "        text = nltk.word_tokenize(text.lower())\n",
    "        token_list.append(text)\n",
    "    dataframes.append(data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234021\n",
      "234021\n"
     ]
    }
   ],
   "source": [
    "print(len(token_list))\n",
    "token_list_removed = removeElements([x for sent in token_list for x in sent], 11)\n",
    "print(len(token_list))\n",
    "\n",
    "word_set = list(dict.fromkeys(set(token_list_removed)))\n",
    "[word_index_dict, index_word_dict] = get_dict(word_set)\n",
    "sequence_len = len(max(token_list, key=len))\n",
    "    \n",
    "    \n",
    "# data.to_csv(join(data_dir, file_name[:-4] + '.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes[0]\n",
    "sorted_users = np.sort(df.user_id.unique())\n",
    "user_remap = dict(zip(sorted_users, range(len(sorted_users))))\n",
    "sorted_products = np.sort(df.product_id.unique())\n",
    "product_remap = dict(zip(sorted_products, range(len(sorted_products))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9200</td>\n",
       "      <td>77458</td>\n",
       "      <td>5.0</td>\n",
       "      <td>love this book too have read it again</td>\n",
       "      <td>0 1 2 3 4 5 6 7 80611 80611 80611 80611 80611 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>10646</td>\n",
       "      <td>49714</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i really enjoyed this book . : )</td>\n",
       "      <td>8 9 10 1 2 11 12 13 80611 80611 80611 80611 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>7995</td>\n",
       "      <td>11002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fast paced and a load of action .</td>\n",
       "      <td>14 15 16 17 18 19 20 11 80611 80611 80611 8061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1707</td>\n",
       "      <td>36253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fun , somewhat predictable , but very enjoyable</td>\n",
       "      <td>21 22 23 24 22 25 26 27 80611 80611 80611 8061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>15531</td>\n",
       "      <td>22206</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great series.love hunter my favorite boyfriend...</td>\n",
       "      <td>28 29 30 31 32 33 34 11 80611 80611 80611 8061...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  rating  \\\n",
       "6      9200       77458     5.0   \n",
       "14    10646       49714     5.0   \n",
       "37     7995       11002     5.0   \n",
       "46     1707       36253     4.0   \n",
       "76    15531       22206     5.0   \n",
       "\n",
       "                                               review  \\\n",
       "6               love this book too have read it again   \n",
       "14                   i really enjoyed this book . : )   \n",
       "37                  fast paced and a load of action .   \n",
       "46    fun , somewhat predictable , but very enjoyable   \n",
       "76  great series.love hunter my favorite boyfriend...   \n",
       "\n",
       "                                       tokenized_text  \n",
       "6   0 1 2 3 4 5 6 7 80611 80611 80611 80611 80611 ...  \n",
       "14  8 9 10 1 2 11 12 13 80611 80611 80611 80611 80...  \n",
       "37  14 15 16 17 18 19 20 11 80611 80611 80611 8061...  \n",
       "46  21 22 23 24 22 25 26 27 80611 80611 80611 8061...  \n",
       "76  28 29 30 31 32 33 34 11 80611 80611 80611 8061...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_text_to_code(x):\n",
    "    tokenization = nltk.word_tokenize(x.lower())\n",
    "    eof_code = len(word_index_dict)  # used to filled in the blank to make up a sentence with seq_len\n",
    "    index = 0\n",
    "    code_int = []\n",
    "    for word in tokenization:\n",
    "        try:\n",
    "            code_int.append(int(word_index_dict[word]))\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "        index += 1\n",
    "    while index < sequence_len:\n",
    "        code_int.append(int(eof_code))\n",
    "        index += 1\n",
    "    return code_int\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df, file_name in tqdm(zip(dataframes, file_names)):\n",
    "    df['tokenized_text'] = df['review'].apply(lambda x: apply_text_to_code(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = dataframes[0]\n",
    "sorted_users = np.sort(df.user_id.unique())\n",
    "user_remap = dict(zip(sorted_users, range(len(sorted_users))))\n",
    "sorted_products = np.sort(df.product_id.unique())\n",
    "product_remap = dict(zip(sorted_products, range(len(sorted_products))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df, file_name in zip(dataframes, file_names):\n",
    "    df.user_id = df.user_id.map(user_remap)\n",
    "    df.product_id = df.product_id.map(product_remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per ora ho eliminato le frasi che contenevano una parola che appariva meno di 10 volte. Non ho usato l'out of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655934"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataframes[0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95296"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>195473</td>\n",
       "      <td>13852</td>\n",
       "      <td>3915</td>\n",
       "      <td>5.0</td>\n",
       "      <td>could n't put it down . based on a true story ...</td>\n",
       "      <td>[4582, 1111, 8227, 5888, 4708, 1794, 7612, 565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649405</td>\n",
       "      <td>13852</td>\n",
       "      <td>1563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i read the book and historical it was good , w...</td>\n",
       "      <td>[2713, 8630, 1984, 6997, 9293, 6934, 5888, 103...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id  rating  \\\n",
       "195473    13852        3915     5.0   \n",
       "649405    13852        1563     4.0   \n",
       "\n",
       "                                                   review  \\\n",
       "195473  could n't put it down . based on a true story ...   \n",
       "649405  i read the book and historical it was good , w...   \n",
       "\n",
       "                                           tokenized_text  \n",
       "195473  [4582, 1111, 8227, 5888, 4708, 1794, 7612, 565...  \n",
       "649405  [2713, 8630, 1984, 6997, 9293, 6934, 5888, 103...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0][dataframes[0]['user_id'] == 13852]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2713'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_dict['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_word_dict['2713']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df, file_name in zip(dataframes, file_names):\n",
    "    df.to_csv(join(data_dir, file_name[:-4] + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "config_dict['seq_len'] = sequence_len\n",
    "config_dict['vocabulary_size'] = len(word_index_dict) + 1\n",
    "config_dict['user_num'] = len(sorted_users)\n",
    "config_dict['product_num'] = len(sorted_products)\n",
    "\n",
    "write_json(join(data_dir, 'word_index_dict.json'), word_index_dict)\n",
    "write_json(join(data_dir, 'index_word_dict.json'), index_word_dict)\n",
    "write_json(join(data_dir, 'config.json'), config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "df = dataframes[0]\n",
    "token_stream = df[['user_id', 'product_id', 'rating', 'tokenized_text']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>4065</td>\n",
       "      <td>5.0</td>\n",
       "      <td>really like all of the joe dillard series</td>\n",
       "      <td>[7726, 5563, 5734, 10891, 4671, 9420, 10743, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7436.0</td>\n",
       "      <td>2744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pretty terrible . at least it was ago</td>\n",
       "      <td>[6446, 10528, 3032, 6325, 6456, 5276, 245, 686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4582.0</td>\n",
       "      <td>822</td>\n",
       "      <td>5.0</td>\n",
       "      <td>excellent read ! will continue the series .</td>\n",
       "      <td>[8246, 5744, 7398, 2755, 9035, 4671, 7771, 303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7114.0</td>\n",
       "      <td>2937</td>\n",
       "      <td>5.0</td>\n",
       "      <td>omg , this was a great read .</td>\n",
       "      <td>[9320, 9923, 3951, 245, 154, 3921, 5744, 3032,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>10416.0</td>\n",
       "      <td>4661</td>\n",
       "      <td>5.0</td>\n",
       "      <td>really cute . loved it start to finish</td>\n",
       "      <td>[7726, 5330, 3032, 624, 5276, 8435, 5312, 2344...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  product_id  rating                                       review  \\\n",
       "2    2225.0        4065     5.0    really like all of the joe dillard series   \n",
       "3    7436.0        2744     1.0        pretty terrible . at least it was ago   \n",
       "14   4582.0         822     5.0  excellent read ! will continue the series .   \n",
       "20   7114.0        2937     5.0                omg , this was a great read .   \n",
       "27  10416.0        4661     5.0       really cute . loved it start to finish   \n",
       "\n",
       "                                       tokenized_text  \n",
       "2   [7726, 5563, 5734, 10891, 4671, 9420, 10743, 7...  \n",
       "3   [6446, 10528, 3032, 6325, 6456, 5276, 245, 686...  \n",
       "14  [8246, 5744, 7398, 2755, 9035, 4671, 7771, 303...  \n",
       "20  [9320, 9923, 3951, 245, 154, 3921, 5744, 3032,...  \n",
       "27  [7726, 5330, 3032, 624, 5276, 8435, 5312, 2344...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_batch = int(len(token_stream) / batch_size)\n",
    "token_stream = token_stream[:num_batch * batch_size]\n",
    "sequence_batches = np.split(np.array(token_stream), num_batch, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9200, 77458, 5.0,\n",
       "       '0 1 2 3 4 5 6 7 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 80611 \\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_batches[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
